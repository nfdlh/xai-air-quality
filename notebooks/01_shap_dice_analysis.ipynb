{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Air Quality Analysis - Beijing Dongsi Station\n",
    "\n",
    "**Course**: WQF7009 Explainable Artificial Intelligence (XAI)  \n",
    "**University**: University of Malaya  \n",
    "**Dataset**: Beijing Multi-Site Air Quality - Dongsi Station (Urban Center)  \n",
    "**Target**: PM2.5 Prediction (Regression)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Imports](#1-setup--imports)\n",
    "2. [Load Data](#2-load-data)\n",
    "3. [Exploratory Data Analysis (EDA)](#3-exploratory-data-analysis-eda)\n",
    "4. [Data Preprocessing](#4-data-preprocessing)\n",
    "5. [Model Training (XGBoost)](#5-model-training-xgboost)\n",
    "6. [Model Evaluation](#6-model-evaluation)\n",
    "7. [SHAP Explanation (Feature Importance)](#7-shap-explanation-feature-importance)\n",
    "8. [DiCE Counterfactual Explanation](#8-dice-counterfactual-explanation)\n",
    "9. [Summary & Conclusions](#9-summary--conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# XAI Methods\n",
    "import shap\n",
    "import dice_ml\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data\n",
    "\n",
    "**Dataset**: Beijing Multi-Site Air Quality - Dongsi Station  \n",
    "**Source**: UCI Machine Learning Repository  \n",
    "**Rows**: 35,064 hourly observations (March 2013 - February 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dongsi station data\n",
    "DATA_PATH = '../beijing-multisite-uci/raw/PRSA_Data_20130301-20170228/PRSA_Data_Dongsi_20130301-20170228.csv'\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"Rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Columns: {df_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column descriptions\n",
    "column_descriptions = {\n",
    "    'No': 'Row index (to drop)',\n",
    "    'year': 'Year (to combine into datetime)',\n",
    "    'month': 'Month (feature)',\n",
    "    'day': 'Day (to combine into datetime)',\n",
    "    'hour': 'Hour (feature)',\n",
    "    'PM2.5': 'TARGET - Fine particulate matter (Âµg/mÂ³)',\n",
    "    'PM10': 'Coarse particulate matter (Âµg/mÂ³)',\n",
    "    'SO2': 'Sulfur dioxide (Âµg/mÂ³)',\n",
    "    'NO2': 'Nitrogen dioxide (Âµg/mÂ³)',\n",
    "    'CO': 'Carbon monoxide (Âµg/mÂ³)',\n",
    "    'O3': 'Ozone (Âµg/mÂ³)',\n",
    "    'TEMP': 'Temperature (Â°C)',\n",
    "    'PRES': 'Atmospheric pressure (hPa)',\n",
    "    'DEWP': 'Dew point temperature (Â°C)',\n",
    "    'RAIN': 'Precipitation (mm)',\n",
    "    'wd': 'Wind direction (16 categories)',\n",
    "    'WSPM': 'Wind speed (m/s)',\n",
    "    'station': 'Station name (constant - Dongsi)'\n",
    "}\n",
    "\n",
    "for col, desc in column_descriptions.items():\n",
    "    print(f\"{col:10} : {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = (missing / len(df_raw) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution (PM2.5)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_raw['PM2.5'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('PM2.5 (Âµg/mÂ³)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of PM2.5')\n",
    "axes[0].axvline(df_raw['PM2.5'].mean(), color='red', linestyle='--', label=f\"Mean: {df_raw['PM2.5'].mean():.1f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df_raw['PM2.5'].dropna())\n",
    "axes[1].set_ylabel('PM2.5 (Âµg/mÂ³)')\n",
    "axes[1].set_title('PM2.5 Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/pm25_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"PM2.5 Statistics:\")\n",
    "print(f\"  Mean: {df_raw['PM2.5'].mean():.2f} Âµg/mÂ³\")\n",
    "print(f\"  Median: {df_raw['PM2.5'].median():.2f} Âµg/mÂ³\")\n",
    "print(f\"  Std: {df_raw['PM2.5'].std():.2f} Âµg/mÂ³\")\n",
    "print(f\"  Min: {df_raw['PM2.5'].min():.2f} Âµg/mÂ³\")\n",
    "print(f\"  Max: {df_raw['PM2.5'].max():.2f} Âµg/mÂ³\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind direction distribution\n",
    "wd_counts = df_raw['wd'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "wd_counts.plot(kind='bar', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Wind Direction')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Wind Direction Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/wind_direction_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWind directions: {df_raw['wd'].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (numerical features only)\n",
    "numerical_cols = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
    "corr_matrix = df_raw[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix - Air Quality Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with PM2.5\n",
    "pm25_corr = corr_matrix['PM2.5'].drop('PM2.5').sort_values(key=abs, ascending=False)\n",
    "print(\"\\nCorrelation with PM2.5:\")\n",
    "for feat, corr in pm25_corr.items():\n",
    "    print(f\"  {feat:8}: {corr:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM2.5 by hour of day\n",
    "hourly_pm25 = df_raw.groupby('hour')['PM2.5'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "hourly_pm25.plot(kind='bar', edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average PM2.5 (Âµg/mÂ³)')\n",
    "plt.title('Average PM2.5 by Hour of Day')\n",
    "plt.xticks(rotation=0)\n",
    "plt.axhline(hourly_pm25.mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/pm25_by_hour.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM2.5 by month\n",
    "monthly_pm25 = df_raw.groupby('month')['PM2.5'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "monthly_pm25.plot(kind='bar', edgecolor='black', alpha=0.7, color='coral')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average PM2.5 (Âµg/mÂ³)')\n",
    "plt.title('Average PM2.5 by Month')\n",
    "plt.xticks(rotation=0)\n",
    "plt.axhline(monthly_pm25.mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/pm25_by_month.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSeasonal Pattern:\")\n",
    "print(f\"  Winter (Dec-Feb) avg: {df_raw[df_raw['month'].isin([12, 1, 2])]['PM2.5'].mean():.1f} Âµg/mÂ³\")\n",
    "print(f\"  Summer (Jun-Aug) avg: {df_raw[df_raw['month'].isin([6, 7, 8])]['PM2.5'].mean():.1f} Âµg/mÂ³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create datetime column\n",
    "df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop unnecessary columns\n",
    "columns_to_drop = ['No', 'year', 'day', 'station', 'datetime']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Columns after dropping: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing values\n",
    "print(\"Missing values before:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing target (PM2.5)\n",
    "df = df.dropna(subset=['PM2.5'])\n",
    "\n",
    "# For other features, fill with median (numerical) or mode (categorical)\n",
    "numerical_features = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
    "for col in numerical_features:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill missing wind direction with mode\n",
    "df['wd'] = df['wd'].fillna(df['wd'].mode()[0])\n",
    "\n",
    "print(f\"\\nMissing values after: {df.isnull().sum().sum()}\")\n",
    "print(f\"Final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define features and target\n",
    "TARGET = 'PM2.5'\n",
    "\n",
    "FEATURES = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM', 'wd', 'hour', 'month']\n",
    "\n",
    "print(f\"Target: {TARGET}\")\n",
    "print(f\"Features ({len(FEATURES)}): {FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Prepare X and y\n",
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature types:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert 'wd' to category type for XGBoost\n",
    "X['wd'] = X['wd'].astype('category')\n",
    "\n",
    "print(f\"Wind direction categories: {X['wd'].cat.categories.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train/Validation/Test split (70/15/15)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)  # 0.176 * 0.85 â‰ˆ 0.15\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Val set:   {X_val.shape[0]:,} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:  {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save processed data\n",
    "train_data = X_train.copy()\n",
    "train_data[TARGET] = y_train\n",
    "train_data.to_csv('../data/processed/train.csv', index=False)\n",
    "\n",
    "val_data = X_val.copy()\n",
    "val_data[TARGET] = y_val\n",
    "val_data.to_csv('../data/processed/val.csv', index=False)\n",
    "\n",
    "test_data = X_test.copy()\n",
    "test_data[TARGET] = y_test\n",
    "test_data.to_csv('../data/processed/test.csv', index=False)\n",
    "\n",
    "print(\"Processed data saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of preprocessing\n",
    "print(\"=\"*60)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Final rows: {len(X):,}\")\n",
    "print(f\"Rows removed: {df_raw.shape[0] - len(X):,}\")\n",
    "print(f\"\\nFeatures: {len(FEATURES)}\")\n",
    "print(f\"  - Pollutants (5): PM10, SO2, NO2, CO, O3\")\n",
    "print(f\"  - Weather (5): TEMP, PRES, DEWP, RAIN, WSPM\")\n",
    "print(f\"  - Wind (1): wd (categorical)\")\n",
    "print(f\"  - Temporal (2): hour, month\")\n",
    "print(f\"\\nTarget: {TARGET}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Training (XGBoost)\n",
    "\n",
    "**Model**: XGBoost Regressor (black-box model)  \n",
    "**Why XGBoost**:\n",
    "- Handles mixed features (categorical + numerical)\n",
    "- Strong baseline performance for tabular data\n",
    "- Black-box nature suitable for XAI demonstration\n",
    "- SHAP has optimized TreeExplainer for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    enable_categorical=True,  # Enable native categorical support\n",
    "    tree_method='hist'  # Required for categorical support\n",
    ")\n",
    "\n",
    "print(\"XGBoost model initialized with parameters:\")\n",
    "print(f\"  n_estimators: 200\")\n",
    "print(f\"  max_depth: 6\")\n",
    "print(f\"  learning_rate: 0.1\")\n",
    "print(f\"  enable_categorical: True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training XGBoost model...\")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "MODEL_PATH = '../models/xgboost_model.pkl'\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "print(f\"Model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "val_metrics = evaluate_model(y_val, y_val_pred, \"Validation\")\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics summary table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Dataset': ['Train', 'Validation', 'Test'],\n",
    "    'RMSE': [train_metrics['RMSE'], val_metrics['RMSE'], test_metrics['RMSE']],\n",
    "    'MAE': [train_metrics['MAE'], val_metrics['MAE'], test_metrics['MAE']],\n",
    "    'RÂ²': [train_metrics['R2'], val_metrics['R2'], test_metrics['R2']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "datasets = [\n",
    "    (y_train, y_train_pred, 'Training'),\n",
    "    (y_val, y_val_pred, 'Validation'),\n",
    "    (y_test, y_test_pred, 'Test')\n",
    "]\n",
    "\n",
    "for ax, (y_true, y_pred, name) in zip(axes, datasets):\n",
    "    ax.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual PM2.5')\n",
    "    ax.set_ylabel('Predicted PM2.5')\n",
    "    ax.set_title(f'{name} Set')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[0].scatter(y_test_pred, residuals, alpha=0.3, s=10)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted PM2.5')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Residuals vs Predicted')\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Residuals')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Residual Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/residual_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from XGBoost (built-in)\n",
    "importance = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': FEATURES,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Feature Importance (Gain)')\n",
    "plt.title('XGBoost Built-in Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/xgboost_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. SHAP Explanation (Feature Importance)\n",
    "\n",
    "**Method**: SHAP (SHapley Additive exPlanations)  \n",
    "**Type**: Model-agnostic, Post-hoc, Global + Local  \n",
    "**Question answered**: \"Which features contribute to the prediction and how?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "print(\"Initializing SHAP TreeExplainer...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values (use a subset for faster computation)\n",
    "print(\"Calculating SHAP values (this may take a moment)...\")\n",
    "X_sample = X_test.sample(n=min(1000, len(X_test)), random_state=42)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f\"SHAP values calculated for {len(X_sample)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 SHAP Summary Plot (Global Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - bar\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance (Global)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_summary_bar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - beeswarm\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.title('SHAP Summary Plot (Beeswarm)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_summary_beeswarm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 SHAP Force Plot (Local Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JavaScript for SHAP force plots\n",
    "shap.initjs()\n",
    "\n",
    "# Force plot for a single prediction (high PM2.5)\n",
    "# Find an index with high PM2.5\n",
    "high_pm25_idx = y_test[y_test > y_test.quantile(0.9)].index[0]\n",
    "sample_idx = X_test.index.get_loc(high_pm25_idx) if high_pm25_idx in X_test.index else 0\n",
    "\n",
    "print(f\"Explaining prediction for sample with high PM2.5\")\n",
    "print(f\"Actual PM2.5: {y_test.iloc[sample_idx]:.2f}\")\n",
    "print(f\"Predicted PM2.5: {model.predict(X_test.iloc[[sample_idx]])[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for single prediction\n",
    "shap_explanation = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[sample_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[sample_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "shap.waterfall_plot(shap_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Prediction (High PM2.5)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_waterfall.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 SHAP Comparison: Peak Hour vs Night Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Peak Hour (8 AM) vs Night Time (3 AM)\n",
    "# Find samples for each scenario\n",
    "\n",
    "# Peak hour sample (hour = 8, morning rush)\n",
    "peak_hour_mask = (X_test['hour'] == 8)\n",
    "peak_hour_sample = X_test[peak_hour_mask].sample(1, random_state=42)\n",
    "peak_hour_idx = X_test.index.get_loc(peak_hour_sample.index[0])\n",
    "\n",
    "# Night time sample (hour = 3, late night)\n",
    "night_mask = (X_test['hour'] == 3)\n",
    "night_sample = X_test[night_mask].sample(1, random_state=42)\n",
    "night_idx = X_test.index.get_loc(night_sample.index[0])\n",
    "\n",
    "# Create waterfall plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Peak Hour\n",
    "shap_peak = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[peak_hour_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[peak_hour_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "# Night Time\n",
    "shap_night = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[night_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[night_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "shap.waterfall_plot(shap_peak, show=False)\n",
    "plt.title(f'Peak Hour (8 AM)\\nActual PM2.5: {y_test.iloc[peak_hour_idx]:.1f}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "shap.waterfall_plot(shap_night, show=False)\n",
    "plt.title(f'Night Time (3 AM)\\nActual PM2.5: {y_test.iloc[night_idx]:.1f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_peak_vs_night.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('COMPARISON: Peak Hour (8 AM) vs Night Time (3 AM)')\n",
    "print('='*60)\n",
    "print(f'Peak Hour PM2.5: {y_test.iloc[peak_hour_idx]:.1f} Âµg/mÂ³')\n",
    "print(f'Night Time PM2.5: {y_test.iloc[night_idx]:.1f} Âµg/mÂ³')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 SHAP Comparison: Winter vs Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Winter (December) vs Summer (July)\n",
    "\n",
    "# Winter sample (month = 12)\n",
    "winter_mask = (X_test['month'] == 12)\n",
    "winter_sample = X_test[winter_mask].sample(1, random_state=42)\n",
    "winter_idx = X_test.index.get_loc(winter_sample.index[0])\n",
    "\n",
    "# Summer sample (month = 7)\n",
    "summer_mask = (X_test['month'] == 7)\n",
    "summer_sample = X_test[summer_mask].sample(1, random_state=42)\n",
    "summer_idx = X_test.index.get_loc(summer_sample.index[0])\n",
    "\n",
    "# Create waterfall plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Winter\n",
    "shap_winter = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[winter_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[winter_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "# Summer\n",
    "shap_summer = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[summer_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[summer_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "shap.waterfall_plot(shap_winter, show=False)\n",
    "plt.title(f'Winter (December)\\nActual PM2.5: {y_test.iloc[winter_idx]:.1f}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "shap.waterfall_plot(shap_summer, show=False)\n",
    "plt.title(f'Summer (July)\\nActual PM2.5: {y_test.iloc[summer_idx]:.1f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_winter_vs_summer.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('COMPARISON: Winter (December) vs Summer (July)')\n",
    "print('='*60)\n",
    "print(f'Winter PM2.5: {y_test.iloc[winter_idx]:.1f} Âµg/mÂ³')\n",
    "print(f'Summer PM2.5: {y_test.iloc[summer_idx]:.1f} Âµg/mÂ³')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 SHAP Comparison: High vs Low Pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: High Pollution (>90th percentile) vs Low Pollution (<10th percentile)\n",
    "\n",
    "# High pollution sample\n",
    "high_threshold = y_test.quantile(0.9)\n",
    "high_mask = y_test > high_threshold\n",
    "high_sample = X_test[high_mask].sample(1, random_state=42)\n",
    "high_idx = X_test.index.get_loc(high_sample.index[0])\n",
    "\n",
    "# Low pollution sample\n",
    "low_threshold = y_test.quantile(0.1)\n",
    "low_mask = y_test < low_threshold\n",
    "low_sample = X_test[low_mask].sample(1, random_state=42)\n",
    "low_idx = X_test.index.get_loc(low_sample.index[0])\n",
    "\n",
    "# Create waterfall plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# High Pollution\n",
    "shap_high = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[high_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[high_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "# Low Pollution\n",
    "shap_low = shap.Explanation(\n",
    "    values=explainer.shap_values(X_test.iloc[[low_idx]])[0],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_test.iloc[low_idx].values,\n",
    "    feature_names=FEATURES\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "shap.waterfall_plot(shap_high, show=False)\n",
    "plt.title(f'High Pollution (>90th percentile)\\nActual PM2.5: {y_test.iloc[high_idx]:.1f}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "shap.waterfall_plot(shap_low, show=False)\n",
    "plt.title(f'Low Pollution (<10th percentile)\\nActual PM2.5: {y_test.iloc[low_idx]:.1f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_high_vs_low_pollution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('COMPARISON: High Pollution vs Low Pollution')\n",
    "print('='*60)\n",
    "print(f'High Pollution PM2.5: {y_test.iloc[high_idx]:.1f} Âµg/mÂ³ (Top 10%)')\n",
    "print(f'Low Pollution PM2.5: {y_test.iloc[low_idx]:.1f} Âµg/mÂ³ (Bottom 10%)')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 SHAP Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plots for top features\n",
    "top_features = ['CO', 'PM10', 'NO2', 'TEMP']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for ax, feature in zip(axes.flatten(), top_features):\n",
    "    shap.dependence_plot(feature, shap_values, X_sample, ax=ax, show=False)\n",
    "    ax.set_title(f'SHAP Dependence: {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_dependence_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 SHAP Analysis for Wind Direction (wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values by wind direction\n",
    "# Get the index of 'wd' feature\n",
    "wd_idx = FEATURES.index('wd')\n",
    "wd_shap = shap_values[:, wd_idx]\n",
    "\n",
    "# Create DataFrame with wind direction and SHAP values\n",
    "wd_shap_df = pd.DataFrame({\n",
    "    'wd': X_sample['wd'].values,\n",
    "    'SHAP': wd_shap\n",
    "})\n",
    "\n",
    "# Calculate mean SHAP value for each wind direction\n",
    "wd_mean_shap = wd_shap_df.groupby('wd')['SHAP'].mean().sort_values()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if x < 0 else 'red' for x in wd_mean_shap.values]\n",
    "wd_mean_shap.plot(kind='barh', color=colors, edgecolor='black')\n",
    "plt.xlabel('Mean SHAP Value (Impact on PM2.5)')\n",
    "plt.ylabel('Wind Direction')\n",
    "plt.title('SHAP: How Each Wind Direction Affects PM2.5 Prediction')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/01_shap_dice_analysis/shap_wind_direction.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nWind Direction Impact on PM2.5:')\n",
    "print('='*50)\n",
    "print('Directions that REDUCE pollution (negative SHAP):')\n",
    "for wd, val in wd_mean_shap[wd_mean_shap < 0].items():\n",
    "    print(f'  {wd:5}: {val:+.2f}')\n",
    "print('\\nDirections that INCREASE pollution (positive SHAP):')\n",
    "for wd, val in wd_mean_shap[wd_mean_shap >= 0].items():\n",
    "    print(f'  {wd:5}: {val:+.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 SHAP Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis summary\n",
    "mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    'Feature': FEATURES,\n",
    "    'Mean |SHAP|': mean_shap\n",
    "}).sort_values('Mean |SHAP|', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP FEATURE IMPORTANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(shap_importance.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. DiCE Counterfactual Explanation\n",
    "\n",
    "**Method**: DiCE (Diverse Counterfactual Explanations)  \n",
    "**Type**: Model-agnostic, Post-hoc, Local  \n",
    "**Question answered**: \"What minimal changes would result in a different outcome?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DiCE\n",
    "# DiCE requires a DataFrame with both features and target\n",
    "\n",
    "# Create a sample dataset for DiCE\n",
    "dice_data = X_train.copy()\n",
    "dice_data[TARGET] = y_train\n",
    "\n",
    "# Convert categorical to string for DiCE\n",
    "dice_data['wd'] = dice_data['wd'].astype(str)\n",
    "\n",
    "print(f\"DiCE data shape: {dice_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature types for DiCE\n",
    "continuous_features = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
    "categorical_features = ['wd', 'hour', 'month']\n",
    "\n",
    "# Create DiCE data object\n",
    "d = dice_ml.Data(\n",
    "    dataframe=dice_data,\n",
    "    continuous_features=continuous_features,\n",
    "    outcome_name=TARGET\n",
    ")\n",
    "\n",
    "print(\"DiCE Data object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
"# Create a wrapper model for DiCE\n",
     "# DiCE converts columns to 'object' type, but XGBoost needs proper types\n",
     "\n",
     "class ModelWrapper:\n",
     "    def __init__(self, model, cat_feature='wd', cat_categories=None, continuous_features=None):\n",
     "        self.model = model\n",
     "        self.cat_feature = cat_feature\n",
     "        self.cat_categories = cat_categories\n",
     "        self.continuous_features = continuous_features or []\n",
     "    \n",
     "    def predict(self, X):\n",
     "        X_copy = X.copy()\n",
     "        \n",
     "        # Convert continuous features to float (DiCE may convert them to object)\n",
     "        for col in self.continuous_features:\n",
     "            if col in X_copy.columns:\n",
     "                X_copy[col] = pd.to_numeric(X_copy[col], errors='coerce')\n",
     "        \n",
     "        # Convert integer features\n",
     "        for col in ['hour', 'month']:\n",
     "            if col in X_copy.columns:\n",
     "                X_copy[col] = pd.to_numeric(X_copy[col], errors='coerce').astype(int)\n",
     "        \n",
     "        # Convert categorical feature\n",
     "        if self.cat_feature in X_copy.columns:\n",
     "            X_copy[self.cat_feature] = pd.Categorical(\n",
     "                X_copy[self.cat_feature], \n",
     "                categories=self.cat_categories\n",
     "            )\n",
     "        \n",
     "        return self.model.predict(X_copy)\n",
     "\n",
     "# Get categories from training data\n",
     "wd_categories = X_train['wd'].cat.categories.tolist()\n",
     "wrapped_model = ModelWrapper(model, 'wd', wd_categories, continuous_features)\n",
     "\n",
     "# Create DiCE model object\n",
     "m = dice_ml.Model(model=wrapped_model, backend='sklearn', model_type='regressor')\n",
     "\n",
     "print(\"DiCE Model object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DiCE explainer\n",
    "exp = dice_ml.Dice(d, m, method='random')\n",
    "\n",
    "print(\"DiCE Explainer created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a high pollution instance to explain\n",
    "# Find a sample with high PM2.5 (above 90th percentile)\n",
    "high_pollution_mask = y_test > y_test.quantile(0.9)\n",
    "high_pollution_samples = X_test[high_pollution_mask].head(1)\n",
    "\n",
    "# Convert to format DiCE expects\n",
    "query_instance = high_pollution_samples.copy()\n",
    "query_instance['wd'] = query_instance['wd'].astype(str)\n",
    "\n",
    "print(\"Query instance (High Pollution):\")\n",
    "print(query_instance)\n",
    "print(f\"\\nActual PM2.5: {y_test[high_pollution_samples.index[0]]:.2f}\")\n",
    "print(f\"Predicted PM2.5: {model.predict(high_pollution_samples)[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "# Target: reduce PM2.5 to below 50 (Good air quality)\n",
    "\n",
    "print(\"Generating counterfactual explanations...\")\n",
    "print(\"Goal: Reduce PM2.5 from high (>100) to good (<50)\")\n",
    "\n",
    "cf = exp.generate_counterfactuals(\n",
    "    query_instance,\n",
    "    total_CFs=3,\n",
    "    desired_range=[0, 50],  # Target PM2.5 range\n",
    "    features_to_vary=continuous_features + ['wd'],  # Allow these features to change\n",
    "    permitted_range={\n",
    "        'CO': [0, 5000],\n",
    "        'NO2': [0, 200],\n",
    "        'WSPM': [0, 20],\n",
    "        'TEMP': [-20, 40]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nCounterfactuals generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display counterfactuals\n",
    "cf.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save counterfactuals to CSV\n",
    "cf_df = cf.cf_examples_list[0].final_cfs_df\n",
    "cf_df.to_csv('../outputs/tables/counterfactuals.csv', index=False)\n",
    "print(\"Counterfactuals saved to outputs/tables/counterfactuals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret counterfactuals\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COUNTERFACTUAL INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOriginal Instance (High Pollution):\")\n",
    "print(f\"  PM2.5: {y_test[high_pollution_samples.index[0]]:.1f} Âµg/mÂ³ (Unhealthy)\")\n",
    "print(\"\\nTo achieve Good Air Quality (PM2.5 < 50), the model suggests:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "original = query_instance.iloc[0]\n",
    "for i, cf_row in cf_df.iterrows():\n",
    "    print(f\"\\nCounterfactual {i+1}:\")\n",
    "    for col in FEATURES:\n",
    "        if col in cf_row.index:\n",
    "            orig_val = original[col]\n",
    "            cf_val = cf_row[col]\n",
    "            if orig_val != cf_val:\n",
    "                print(f\"  {col}: {orig_val} â†’ {cf_val}\")\n",
    "    print(f\"  Resulting PM2.5: {cf_row[TARGET]:.1f} Âµg/mÂ³\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"XAI AIR QUALITY ANALYSIS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Source: Beijing Dongsi Station (Urban Center)\")\n",
    "print(f\"  Period: March 2013 - February 2017\")\n",
    "print(f\"  Samples: {len(X):,} hourly observations\")\n",
    "print(f\"  Features: {len(FEATURES)} (5 pollutants + 5 weather + 1 wind + 2 temporal)\")\n",
    "print(f\"  Target: PM2.5 (Fine Particulate Matter)\")\n",
    "\n",
    "print(\"\\nðŸ¤– MODEL PERFORMANCE\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Model: XGBoost Regressor\")\n",
    "print(f\"  Test RMSE: {test_metrics['RMSE']:.4f}\")\n",
    "print(f\"  Test MAE: {test_metrics['MAE']:.4f}\")\n",
    "print(f\"  Test RÂ²: {test_metrics['R2']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ” SHAP INSIGHTS (Feature Importance)\")\n",
    "print(\"-\"*70)\n",
    "print(\"  Top 5 Important Features:\")\n",
    "for i, row in shap_importance.head(5).iterrows():\n",
    "    print(f\"    {i+1}. {row['Feature']}: {row['Mean |SHAP|']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ”„ COUNTERFACTUAL INSIGHTS (DiCE)\")\n",
    "print(\"-\"*70)\n",
    "print(\"  To reduce PM2.5 from Unhealthy to Good:\")\n",
    "print(\"    - Reduce CO emissions (traffic, industry)\")\n",
    "print(\"    - Increase wind speed (natural dispersion)\")\n",
    "print(\"    - Wind direction change (NW clears pollution)\")\n",
    "\n",
    "print(\"\\nðŸ“ OUTPUTS GENERATED\")\n",
    "print(\"-\"*70)\n",
    "print(\"  Figures:\")\n",
    "print(\"    - outputs/figures/pm25_distribution.png\")\n",
    "print(\"    - outputs/figures/correlation_matrix.png\")\n",
    "print(\"    - outputs/figures/shap_summary_bar.png\")\n",
    "print(\"    - outputs/figures/shap_summary_beeswarm.png\")\n",
    "print(\"    - outputs/figures/shap_waterfall.png\")\n",
    "print(\"    - outputs/figures/shap_dependence_plots.png\")\n",
    "print(\"  Tables:\")\n",
    "print(\"    - outputs/tables/counterfactuals.csv\")\n",
    "print(\"  Model:\")\n",
    "print(\"    - models/xgboost_model.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
